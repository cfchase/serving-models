{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad2cc4e-31ec-4648-b0fe-6632f2bdbc36",
   "metadata": {},
   "source": [
    "# Using the OpenAI API\n",
    " \n",
    "This notebook demonstrates how to interact with a Large Language Model (LLM) through the OpenAI API. While you may be familiar with using LLMs through user interfaces like ChatGPT, this notebook shows how to programmatically interact with an LLM using the [OpenAI Python SDK](https://platform.openai.com/docs/libraries?language=python)\n",
    "\n",
    "The notebook will walk you through:\n",
    "1. Setting up the OpenAI client\n",
    "2. Configuring the endpoint and API key\n",
    "3. Making a simple chat completion request\n",
    "4. Processing the streaming response\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4e2b81-0e10-4390-a7b8-5ddfda53a3e3",
   "metadata": {},
   "source": [
    "### Requirements and Imports\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2b14bf-7b84-4f6c-9975-390d143ad3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c428fbad-2345-4536-b687-72416d6b9b15",
   "metadata": {},
   "source": [
    "### OpenAI Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977410bc8950fc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "infer_endpoint = \"https://model.apps.clusterx.sandboxx.opentlc.com\"\n",
    "api_key = \"EMPTY\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=f\"{infer_endpoint}/v1\" #don't forget the /v1\n",
    ")\n",
    "\n",
    "# Get model name of the first available model\n",
    "# Since we're using OpenShift AI serving with vLLM, there is only one model available\n",
    "model_list = client.models.list()\n",
    "model_name = model_list.data[0].id\n",
    "print(f\"Using model: {model_name}\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        # User message\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hi. Who are you?\"\n",
    "        }\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end='', flush=True)\n",
    "print()\n",
    "\n",
    "# print(completion.choices[0].message) #stream=False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
